# ğŸ‡®ğŸ‡¹ Qwen3-TTS Italian Fine-Tuning

Fine-tune [Qwen3-TTS](https://github.com/QwenLM/Qwen3-TTS) for Italian voice on Vast.ai GPU cloud.

**15,000 Italian audio samples** | **~$1.20 total cost** | **2.5 hours training time**

## âš¡ One-Command Setup

```bash
curl -sSL https://raw.githubusercontent.com/OhMySimo/Qwen3-TTS-finetuning/main/setup_vast.sh | bash
```

Then start training:

```bash
cd /workspace/Qwen3-TTS-finetuning/finetuning
./train_vast.sh
```

## ğŸ“Š What You Get

- âœ… Professional Italian TTS model
- âœ… Auto-configured for 4x or 8x RTX 3090
- âœ… Pre-processed dataset included
- âœ… Optimized training scripts
- âœ… Monitoring & validation tools

## ğŸš€ Quick Start

### 1. Rent GPUs on Vast.ai

- Search: `4x RTX 3090` (recommended)
- Template: NVIDIA CUDA Development Environment
- Cost: ~$0.48/hour

### 2. SSH into instance and run setup

```bash
curl -sSL https://raw.githubusercontent.com/OhMySimo/Qwen3-TTS-finetuning/main/setup_vast.sh | bash
```

### 3. Start training

```bash
cd /workspace/Qwen3-TTS-finetuning/finetuning
./train_vast.sh
```

### 4. Download your model

```bash
tar -czf checkpoint.tar.gz output_italian_tts/checkpoint-best
scp -P <PORT> root@<IP>:/workspace/Qwen3-TTS-finetuning/finetuning/checkpoint.tar.gz .
```

## ğŸ“ Repository Structure

```
finetuning/
â”œâ”€â”€ train_vast.sh          # Main training script (auto-detects GPU count)
â”œâ”€â”€ sft_12hz.py           # Multi-GPU training with Accelerate
â”œâ”€â”€ dataset.py            # Dataset loader
â”œâ”€â”€ prepare_data.py       # Audio tokenization
â”œâ”€â”€ validate_dataset.py   # Dataset validation
â””â”€â”€ monitor_training.sh   # Live GPU/training monitor
```

## ğŸ’¾ Dataset

Italian dataset v2: [Download](https://github.com/OhMySimo/Qwen3-TTS-finetuning/releases/tag/it)

- 15,000 samples
- 24kHz mono audio
- Natural Italian speech
- Ready to use

## âš™ï¸ Training Config

### 4x RTX 3090 (Recommended)
- Batch size: 10 per GPU
- Effective batch: 80
- Time: ~2.5 hours
- Cost: ~$1.20

### 8x RTX 3090 (Faster)
- Batch size: 10 per GPU
- Effective batch: 80
- Time: ~1.25 hours
- Cost: ~$1.20

## ğŸ§ª Use Your Model

```python
import torch
from qwen_tts import Qwen3TTSModel

tts = Qwen3TTSModel.from_pretrained(
    "output_italian_tts/checkpoint-best",
    device_map="cuda:0",
    dtype=torch.bfloat16,
)

wavs, sr = tts.generate_custom_voice(
    text="Ciao! Sono il modello italiano.",
    speaker="italian_multi",
)
```

## ğŸ“š Full Documentation

- [Complete Setup Guide](GUIDE.md)
- [Qwen3-TTS Official](https://github.com/QwenLM/Qwen3-TTS)
- [Vast.ai](https://vast.ai/)

## ğŸ”§ Features

- Multi-GPU training with Accelerate
- Flash Attention 2 support
- 8-bit Adam optimizer (optional)
- Automatic validation & checkpointing
- Tensorboard monitoring
- Early stopping

## ğŸ› ï¸ Troubleshooting

**Out of Memory?**
```bash
# Edit train_vast.sh
BATCH_SIZE_PER_GPU=6
GRAD_ACCUM=4
```

**Training disconnected?**
```bash
# Use tmux
tmux new -s training
./train_vast.sh
# Detach: Ctrl+B, D
# Reattach: tmux attach -t training
```

## ğŸ“„ License

Apache 2.0 (same as Qwen3-TTS)

## ğŸ™ Credits

- [Qwen Team](https://github.com/QwenLM/Qwen3-TTS) for the base model
- Italian dataset created for this project

---

**Questions?** Open an [Issue](https://github.com/OhMySimo/Qwen3-TTS-finetuning/issues)

**Total time from zero to trained model: ~3 hours** â±ï¸
